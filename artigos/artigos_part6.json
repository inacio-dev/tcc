[
  {
    "_comentario": "ESTE É UM EXEMPLO - NÃO PREENCHER, APENAS REFERÊNCIA",
    "_arquivo_parte": "PARTE 6 - Contém artigos 53+. Artigos 1-15 em artigos_part1.json, 16-27 em artigos_part2.json, 28-38 em artigos_part3.json, 39-45 em artigos_part4.json, 46-52 em artigos_part5.json",
    "numero": 0,
    "nome_arquivo": "nome_do_arquivo.pdf",

    "_comentario_artigos_grandes": "Para artigos muito grandes (>10 páginas ou erro 413 na API): 1) Dividir PDF em partes menores (ex: _parte01.pdf, _parte02.pdf); 2) Ler de 3 em 3 partes para não sobrecarregar contexto; 3) Criar arquivo artigoN_resumo.md com resumo detalhado de cada parte; 4) Após processar todas as partes, adicionar entrada resumida aqui no JSON. Exemplo: artigo 9 foi dividido em 8 partes e resumido em artigo9_resumo.md",

    "_comentario_identificacao": "Informações bibliográficas do artigo - NOMES DOS AUTORES DEVEM ESTAR COMPLETOS conforme aparecem no PDF",
    "autores": "Nome Completo; Nome Completo 2 (separados por ponto e vírgula)",
    "ano": 2024,
    "titulo": "Título completo do artigo",
    "subtitulo": "Subtítulo se houver",
    "journal": "Nome do periódico/conferência",
    "publisher": "Editora (Elsevier, IEEE, Springer, etc.)",

    "_comentario_conteudo": "Análise do conteúdo científico",
    "objetivo": "Objetivo principal do artigo - o que os autores buscam resolver/propor",
    "metodologia": "Métodos, algoritmos, arquiteturas e abordagens utilizadas",
    "analise_estatistica": "Métricas, testes estatísticos, tamanho de amostra, distribuições",
    "resultados": "Principais resultados quantitativos e qualitativos",
    "contribuicoes": "Contribuições originais do trabalho",
    "limitacoes": "Limitações identificadas pelos autores ou observadas",

    "_comentario_classificacao": "Classificação e categorização",
    "topico": "Palavras-chave principais (ex: Edge Computing, IoT, Machine Learning)",
    "area_aplicacao": "Domínios de aplicação (ex: Robótica, Veículos Autônomos, Indústria 4.0)",

    "_comentario_recursos": "Recursos práticos e reprodutibilidade",
    "tipo_dados": "Tipo de dados utilizados (ex: Imagens, Séries Temporais, Texto)",
    "dataset": "Nome dos datasets utilizados (se aplicável)",
    "frameworks": "Frameworks, bibliotecas e ferramentas utilizadas",
    "link_codigo": "URL do repositório de código (se disponível)"
  },
  {
    "numero": 53,
    "nome_arquivo": "Use of QUIC for AMQP in IoT networks.pdf",

    "autores": "Faheem Iqbal; Moneeb Gohar; Hanen Karamti; Walid Karamti; Seok-Joo Koh; Jin-Ghoo Choi",
    "ano": 2023,
    "titulo": "Use of QUIC for AMQP in IoT networks",
    "subtitulo": "",
    "journal": "Computer Networks",
    "publisher": "Elsevier",

    "objetivo": "Integrar o protocolo AMQP 1.0 com QUIC para reduzir latência e melhorar vida útil de bateria em dispositivos IoT. O trabalho visa resolver o problema de que TCP não garante tempo real devido ao three-way handshake e uso de TLS para segurança, enquanto UDP não garante confiabilidade. QUIC, padronizado pelo IETF, combina os melhores aspectos de UDP e TCP para fornecer comunicação rápida e confiável. AMQP 1.0 foi selecionado por ser um protocolo extensível e interoperável capaz de lidar com desafios de interconectividade em ambientes IoT heterogêneos.",

    "metodologia": "Implementação em linguagem Go utilizando pacotes nativos AMQP 1.0 e QUIC publicamente acessíveis. Desenvolvimento do pacote qConn para integrar AMQP 1.0 com QUIC, definindo funções Listen e Dial para criar broker, sender e receiver QUIC. Função qConn.Listen() usa quic.ListenAddrEarly() para criar QUIC Broker que retorna conexões antes do handshake completar, permitindo 0-RTT. Função qConn.Dial() usa quic.DialAddrEarly() para estabelecer novas conexões QUIC. Containerização com Docker para AMQP 1.0 Sender, Broker e Receiver. Simulação em NS3 (simulador de rede de eventos discretos) em máquina virtual com 4 processadores, 8GB RAM, Ubuntu 20.04 LTS. Rede WiFi LAN IEEE 802.11a operando a 5GHz com largura de banda de canal de 20MHz e Canal Número 36. Tap Bridges conectando containers Docker como ghost nodes no NS3. Esquema existente: AMQP 1.0 sobre TCP com TLS 1.2 (3-RTT para handshake). Esquema proposto: AMQP 1.0 sobre QUIC com TLS 1.3 integrado (1-RTT para handshake). Cenário de múltiplas conexões AMQP: 100 mensagens por experimento (uma mensagem por conexão), 30 repetições, total de 30000 amostras por esquema. Cenário de conexão única AMQP: 1000 mensagens em uma única conexão. Cenário de análise de energia: 10 conexões por experimento com mensagem de 138 bytes, 15 repetições. Modelo de energia NS3 linear/ideal com fonte de 3V, estados WiFi (Tx, Rx, CCA Busy, Idle, Sleep, Switching, Off). Variação de parâmetros de rede com ferramenta tc: Bandwidth (8, 16, 32, 512, 1024 Kbps), Delay (0, 200, 400, 600 ms), Packet Loss (0, 5, 10, 15%). Traces pcap habilitados no NS3 para coleta de resultados.",

    "analise_estatistica": "KPIs medidos: Total Communication Time (tempo do primeiro ao último pacote), Startup Latency (tempo até primeiro pacote de aplicação útil ser enviado), Round Trip Time (RTT), Throughput (bits/s ou Kbps), Consumo de Energia (J = V × A × s). Múltiplas conexões AMQP (30000 amostras): Total Communication Time para enviar 100 mensagens reduzido em 22% com QUIC; tempo de recebimento reduzido em 15%. Conexão única AMQP (1000 mensagens): RTT 71% maior para QUIC (12ms vs 7ms para TCP), porém Startup Latency reduzida em 62% (120ms QUIC vs 315ms TCP), Total Communication Time reduzida em 21%. Análise de energia (150 conexões totais): consumo médio AMQP/QUIC = 11.64J vs AMQP/TCP = 16.96J, redução de 31%; Total Communication Time AMQP/QUIC = 12.73s vs AMQP/TCP = 19.22s, redução de 34%. Impacto de Delay: em todos os cenários (0-600ms), AMQP/QUIC supera AMQP/TCP; com 600ms de delay, QUIC = 38.01ms vs TCP = 43.74ms. Impacto de Packet Loss: com 0% perda, QUIC = 5.09ms vs TCP = 6ms; com 15% perda, TCP dobra tempo (12.08ms) enquanto QUIC aumenta apenas 50% (7.26ms). Impacto de Channel Bandwidth: em bandas altas (≥32Kbps), QUIC supera TCP; em bandas baixas (<32Kbps), TCP supera QUIC devido ao overhead de segurança do QUIC. Volume de dados: QUIC transmitiu 3.5× mais dados que TCP (1278 KB vs 361 KB); Throughput: QUIC 7× maior que TCP (1216 Kbps vs 173 Kbps). Comparação de protocolos IoT (literatura): MQTT 0.1101s, AMQP 0.1255s, CoAP 0.8661s, HTTP 1.2360s.",

    "resultados": "Integração AMQP 1.0 com QUIC implementada e validada através de testes extensivos em NS3. Total Communication Time reduzido em 22% e Startup Latency reduzida em 62% utilizando QUIC ao invés de TCP na camada de transporte. Apesar do RTT ser 71% maior para QUIC, a melhoria em Startup Latency e Total Communication Time não pode ser atribuída ao RTT, demonstrando que o handshake 1-RTT do QUIC (vs 3-RTT do TCP+TLS) é o fator determinante. Consumo de energia reduzido em 31% usando QUIC. AMQP 1.0 sobre QUIC superou AMQP 1.0 sobre TCP em todos os cenários de delay testados (0-600ms). Em cenários de packet loss, QUIC demonstrou muito maior resiliência: com 15% de perda, TCP dobrou o tempo de comunicação enquanto QUIC aumentou apenas 50%. QUIC supera TCP em altas larguras de banda, porém TCP supera QUIC em baixas larguras de banda (<32Kbps) devido ao maior overhead de segurança do QUIC. AMQP/QUIC transportou 3.5× mais dados que AMQP/TCP, mas throughput foi 7× maior, resultando em menor tempo de comunicação. Os resultados demonstram que, com exceção do cenário de baixa largura de banda, o esquema proposto consistentemente supera o esquema existente. QUIC resolve problemas do TCP em IoT: head of line blocking, half open connections, necessidade de keep-alive packets, e permite connection migration através de Connection ID único.",

    "contribuicoes": "1) Primeira integração de AMQP 1.0 com QUIC, combinando protocolo de aplicação extensível e interoperável com protocolo de transporte rápido e confiável para IoT. 2) Desenvolvimento do pacote qConn em Go com funções Listen e Dial para criar QUIC broker, sender e receiver, utilizando quic.ListenAddrEarly() e quic.DialAddrEarly() para habilitar 0-RTT. 3) Metodologia de teste usando containerização Docker com Tap Bridges em NS3 para simular comunicação WiFi entre componentes AMQP. 4) Análise de energia usando NS3 Energy Framework com modelo de fonte linear, demonstrando redução de 31% no consumo de energia. 5) Avaliação extensiva sob diferentes condições de rede (delay, packet loss, channel bandwidth) com 30000 amostras, demonstrando que QUIC supera TCP em cenários de rede lossy típicos de IoT. 6) Demonstração de que melhoria em Startup Latency (62%) e Total Communication Time (22%) são devidas ao handshake 1-RTT do QUIC vs 3-RTT do TCP+TLS, não ao RTT que é 71% maior para QUIC. 7) Identificação de limitação do QUIC em cenários de baixa largura de banda (<32Kbps) devido ao overhead de segurança, importante para dispositivos IoT constrained. 8) Modificação da implementação Go de AMQP 1.0 para incluir TLS 1.2 conforme especificado no padrão AMQP 1.0.",

    "limitacoes": "Modelo de energia linear/ideal utilizado não representa consumo real de energia em redes de sensores sem fio - modelos não-lineares (como Rakhmatov Vrudhula) fornecem resultados mais precisos. Recursos de multi-streaming e connection migration do QUIC não foram testados - planejados para trabalho futuro. Apenas WiFi 802.11a foi utilizado para comunicação - escolha da versão WiFi específica não é crítica para comparação mas pode não representar todos os cenários IoT. QUIC apresenta pior desempenho que TCP em cenários de baixa largura de banda (<32Kbps) devido ao maior overhead de segurança - limitação importante para dispositivos IoT extremamente constrained. Testes realizados em simulador NS3 com máquina virtual - validação em hardware real (como Raspberry Pi) não foi realizada neste estudo. Comparação limitada a AMQP 1.0 - outros protocolos IoT como MQTT e CoAP também poderiam se beneficiar da integração com QUIC (trabalhos relacionados já existem). Análise de segurança não foi foco do estudo - apenas comparação de desempenho entre TLS 1.2 (TCP) e TLS 1.3 integrado (QUIC).",

    "topico": "QUIC, AMQP, AMQP 1.0, Internet of Things (IoT), Transport Layer Protocol, TCP, UDP, TLS 1.3, Low Latency, Energy Consumption, Docker, NS3 Simulator, WiFi 802.11a, Performance Analysis, Startup Latency, Round Trip Time (RTT), Throughput, Packet Loss, Channel Bandwidth, Delay, Connection Migration, Head of Line Blocking, 0-RTT Handshake, 1-RTT Handshake, Go Programming Language, Tap Bridge, Containerization, Message Broker, Publish/Subscribe, Request/Response, Interoperability, Heterogeneous IoT, Constrained Devices, Battery Life, Wireless Sensor Networks, Smart Cities, Smart Grids",
    "area_aplicacao": "Internet of Things (IoT), Smart Cities, Smart Grids, Telemetry, Smart Manufacturing, Smart Agriculture, Wireless Sensor Networks, Industrial IoT, Remote Surgery, Autonomous Vehicles, Smart Metering, Indoor IoT Applications, Constrained Devices, Battery-Powered Devices, Message Queue Systems, Real-time Communication",

    "tipo_dados": "Total Communication Time (s), Startup Latency (ms), Round Trip Time (ms), Throughput (Kbps), Consumo de Energia (J), Volume de Dados (KB), Taxa de Perda de Pacotes (%), Delay de Rede (ms), Largura de Banda de Canal (Kbps), traces pcap de simulação NS3",
    "dataset": "Não aplicável - simulação em NS3 com 30000 amostras (100 mensagens × 30 experimentos × 2 esquemas) para múltiplas conexões AMQP, e 150 conexões (10 × 15 repetições) para análise de energia",
    "frameworks": "Go programming language (implementação), Pacote AMQP 1.0 Go (github.com/apache/qpid-proton/go/pkg/electron), Pacote QUIC Go (github.com/lucas-clemente/quic-go), Docker (containerização de Sender/Broker/Receiver), NS3 (simulador de rede), NS3 Energy Module (análise de energia), NS3 WiFi Radio Model (modelo de consumo WiFi), tc tool (variação de parâmetros de rede), Tap Bridges (integração Docker-NS3), IEEE 802.11a WiFi (rede de comunicação simulada)",
    "link_codigo": "Não disponível (No data was used for the research described in the article) - Pacotes Go utilizados: https://pkg.go.dev/github.com/apache/qpid-proton/go/pkg/electron e https://pkg.go.dev/github.com/lucas-clemente/quic-go"
  },
  {
    "numero": 54,
    "nome_arquivo": "Visual-haptic feedback for ROV subsea navigation control.pdf",

    "autores": "Pengxiang Xia; Hengxu You; Jing Du",
    "ano": 2023,
    "titulo": "Visual-haptic feedback for ROV subsea navigation control",
    "subtitulo": "",
    "journal": "Automation in Construction",
    "publisher": "Elsevier B.V.",

    "objetivo": "Propor um sistema de augmentação sensorial baseado em Realidade Virtual (VR) com simuladores hápticos para gerar feedback imersivo, intuitivo e efetivo para operadores humanos de ROVs submarinos. O sistema converte parâmetros ambientais submarinos novos (como forças hidrodinâmicas) em sensações humanamente perceptíveis, incluindo simulação de características hidrodinâmicas como feedback visual (campo vetorial em VR) e feedback háptico (vibrações em traje háptico). O objetivo é melhorar a percepção e consciência situacional dos operadores em ambientes submarinos de baixa visibilidade, onde o streaming de vídeo tradicional 2D não consegue fornecer informações adequadas sobre correntes dinâmicas, visibilidade reduzida e interações com ecossistemas marinhos.",

    "metodologia": "Desenvolvimento de ambiente submarino VR em Unity 2020.4.25f baseado no sistema Crest Ocean para simulação de ondas oceânicas de alta fidelidade e renderização de luz submarina. Visibilidade da câmera configurada para 0-5m simulando condições típicas offshore. Unity Visual Effect Graph (VFX) aplicado para simular poeira flutuante usada por operadores para controle de locomoção. Sistema de sensores virtuais com 24 sensores (12 por lado do ROV) mapeados para 40 vibradores do traje háptico bHaptics TactSuit X40. Simulação de fluxo de partículas baseada em dados ADCP (Acoustic Doppler Current Profiler) com 800 partículas ativas e taxa de atualização de 2Hz. Intensidade do fluxo calculada como soma do momento normal: M_sensor = Σm_i*v̂_i, onde m_i é massa da partícula e v̂_i é vetor normal de velocidade perpendicular à superfície de contato. Função de conversão exponencial para mapear intensidade bruta para faixa 0-1: I = (e^(0.33*M_sensor) - 1)/(e^(0.33*M_sensor) + 1). Comunicação Unity-Python via Python-Unity-Socket para enviar dados aos vibradores do traje háptico. Experimento com sujeitos humanos (n=30) em design within-subject com quatro condições: Controle (apenas vídeo streaming com poeira flutuante), Visual (campo vetorial com setas indicando direção e velocidade do fluxo), Háptico (vibrações no traje indicando direção e magnitude do fluxo), Multi-feedback (visual + háptico). Tarefa de navegação em linha reta de 90m com 5 checkpoints e zonas de correntes submarinas de dificuldade crescente (1-3 zonas por segmento). Velocidade média do ROV: 1m/s, tempo estimado sem atrasos: 1.5min. Velocidade média de fluxo calibrada em 0m/s com magnitude máxima de 0.75m/s. Hardware: HTC VIVE HMD com Tobii Pro eye tracker (50Hz), joystick Xbox para controle do ROV, traje háptico bHaptics TactSuit X40. Coleta de dados: trajetória do ROV, checkpoints alcançados, eye tracking (movimento ocular e tamanho pupilar), dados demográficos. Questionários pós-experimento: NASA-TLX (carga de trabalho) e Trust Scale (nível de confiança). Sessão de treinamento repetida 3 vezes antes do experimento formal. Ordem das condições randomizada para eliminar efeito de aprendizado.",

    "analise_estatistica": "Teste de Wilcoxon para todas as comparações devido à violação do pressuposto de normalidade. Análise de poder estatístico para determinação do tamanho mínimo da amostra: nível de significância α=0.05, poder desejado=0.8, tamanho do efeito=0.8, resultando em n≥25 participantes. Desvio médio da linha reta d_avg = Σ|d_i|/I_total onde d_i é o desvio em cada frame e I_total é o número total de frames. Checkpoints alcançados: diferença significativa entre controle e háptico (p<0.0001), controle e visual (p=0.0002), controle e multi-feedback (p<0.0001); não significativa entre háptico e visual (p=0.19), háptico e multi-feedback (p=0.65), visual e multi-feedback (p=0.10). Desvio médio: diferença significativa entre controle e háptico (p<0.0001), controle e visual (p=0.0007), controle e multi-feedback (p<0.0001); não significativa entre háptico e visual (p=0.70), háptico e multi-feedback (p=0.30), visual e multi-feedback (p=0.21). Carga cognitiva (diâmetro pupilar): menor em todas as condições aumentadas vs controle (háptico p<0.0001, visual p=0.0033, multi-feedback p=0.002). NASA-TLX: menor carga de trabalho em todas as condições aumentadas vs controle (háptico p=0.0003, visual p=0.0004, multi-feedback p=0.0006). Trust Scale: diferença significativa controle vs todas as condições aumentadas (p<0.0001); maior confiança no háptico (p=0.047) e multi-feedback (p=0.0002) vs visual. Análise Mann-Whitney para fatores demográficos vs grupos de preferência: gênero (p=0.55), formação acadêmica (p=0.76), experiência VR/3D gaming (p=0.25), idade (p=0.96) - nenhuma relação significativa encontrada. Análise por grupo de preferência: grupo háptico (n=17, 56.67%) mostrou desempenho significativamente melhor com feedback háptico vs visual (checkpoints p=0.0052, desvio p=0.0079); grupo visual (n=13, 43.33%) mostrou menor desvio com visual vs háptico (p=0.0012).",

    "resultados": "Desvio médio por metro navegado: Controle=7.739m, Háptico=2.714m (redução de 65%), Visual=3.514m (redução de 55%), Multi-feedback=2.282m (redução de 70%). Checkpoints alcançados significativamente maiores com qualquer método de feedback aumentado comparado ao controle (média ~4.5 vs ~2 no controle). Carga cognitiva (diâmetro pupilar) significativamente menor com feedback aumentado, indicando menor esforço mental. NASA-TLX confirmou menor carga de trabalho percebida em todas as condições aumentadas. Trust Scale: maior confiança reportada com feedback háptico e multi-feedback comparado ao visual. Preferências dos participantes: 43.34% preferiu multi-feedback, 33.33% háptico, 23.33% visual, 0% controle. Problemas reportados: 26.67% problemas com intensidade háptica (muito forte ou fraco), 33.33% problemas com visual (confuso ou bloqueando visão), 10% problemas com ambos, 30% sem problemas. Análise por grupo de preferência revelou diferenças significativas: grupo com preferência háptica teve desempenho significativamente melhor com feedback háptico vs visual; grupo com preferência visual teve menor desvio com visual vs háptico, mas não mostrou maior confiança no sistema visual. Grupo de preferência háptica: não houve diferença significativa entre controle e visual (p=0.093 checkpoints, p=0.26 desvio), indicando que feedback visual não é efetivo para este grupo. Grupo de preferência visual: multi-feedback teve maior confiança que visual (p=0.017) e háptico (p=0.030), indicando que combinação é preferível mesmo para quem tem inclinação visual. Nenhuma relação encontrada entre preferência de feedback e fatores demográficos (gênero, idade, formação, experiência VR).",

    "contribuicoes": "1) Primeiro sistema integrado de VR-háptico para teleoperação de ROV submarino que converte dados hidrodinâmicos em feedback sensorial multimodal (visual e háptico) humanamente perceptível. 2) Metodologia para simulação de fluxo de partículas baseada em dados ADCP com sistema de sensores virtuais mapeados para traje háptico, usando soma de momento normal para calcular intensidade de fluxo. 3) Evidência experimental robusta (n=30, design within-subject) de que augmentação sensorial (visual, háptica ou combinada) melhora significativamente desempenho de navegação ROV (redução de 55-70% no desvio), reduz carga cognitiva e aumenta confiança do operador. 4) Descoberta de diferenças individuais significativas nas preferências de feedback (visual vs háptico) que afetam efetividade do método: 56.67% preferem háptico, 43.33% preferem visual. 5) Demonstração de que desempenho e percepção variam significativamente entre grupos de preferência: feedback não-preferido pode não fornecer benefício significativo sobre condição controle. 6) Recomendações de design para sistemas de feedback multi-modal em teleoperação ROV: fornecer ambos feedback visual e háptico com função ON/OFF, usar háptico como feedback fundamental para indicação de condições hidrodinâmicas, visual como indicador de campo distante e háptico como indicador de interações próximas. 7) Framework de conversão de dados hidrodinâmicos para feedback háptico usando função exponencial para mapeamento de intensidade e Python-Unity-Socket para comunicação em tempo real. 8) Demonstração de que causas raiz das preferências individuais não são explicadas por fatores demográficos tradicionais (gênero, idade, formação, experiência VR).",

    "limitacoes": "Experimento testou apenas tarefa simples de navegação em linha reta - não representa tarefas complexas de estabilização, acoplamento ou interação física com ambiente submarino. Sistema não testado com ROV real em produção, apenas em simulação VR de alta fidelidade. Causa raiz das preferências individuais (visual vs háptico) não foi identificada - nenhuma relação com gênero, idade, formação acadêmica ou experiência com VR/3D gaming. Padrões de fluxo pré-projetados com velocidade média calibrada em 0m/s e magnitude máxima de 0.75m/s - não testado com dados oceânicos reais em tempo real. Intensidade háptica reportada como inadequada por 26.67% dos participantes (muito forte ou muito fraca) - necessita calibração personalizada. Feedback visual reportado como confuso ou bloqueando visão por 33.33% dos participantes. Trabalho futuro planejado: desenvolver sistema de teleoperação ROV real com BlueROV2 mini class, testar em operações ROV complexas, melhorar resolução de dados de simulação e desenvolver métodos de controle mais intuitivos. Sistema de partículas com 800 partículas ativas e taxa de atualização de 2Hz pode não capturar dinâmicas de fluxo de alta frequência. Participantes eram majoritariamente de background de engenharia (83.3%) com idade média de 25.2 anos - pode não representar população geral de operadores ROV.",

    "topico": "Visual-haptic Feedback, ROV Teleoperation, Virtual Reality, Sensory Augmentation, Human-Robot Interaction, Subsea Engineering, Hydrodynamic Sensing, Particle Flow Simulation, Vector Field Visualization, Haptic Suit, bHaptics, Unity Game Engine, Eye Tracking, Pupillary Dilation, Cognitive Load, NASA-TLX, Trust Scale, Within-Subject Design, Wilcoxon Test, Individual Differences, Feedback Preference, Navigation Control, Anti-drifting, Low Visibility Environment, Underwater Robotics, Offshore Engineering, Pipeline Inspection, Ocean Exploration, Crest Ocean System, Python-Unity-Socket, Virtual Sensors, ADCP Data, Multi-modal Feedback",
    "area_aplicacao": "Subsea Engineering, Offshore Oil and Gas, Pipeline Inspection, Ocean Exploration, Underwater Construction, Subsea Maintenance, Marine Science, ROV Operations, Underwater Intervention, Remote Teleoperation, Seafloor Mining, Maritime Transport, Aquaculture, Sustainability, Disaster Preparedness, Underwater Cabling",

    "tipo_dados": "Trajetórias de navegação ROV (posição x,y ao longo do tempo), checkpoints alcançados (contagem), desvio da linha reta (m), dados de eye tracking (movimento ocular e tamanho pupilar a 50Hz), questionários NASA-TLX (escala 0-100), questionários Trust Scale, dados demográficos (gênero, idade, formação, experiência VR), preferências de feedback auto-reportadas, problemas/preocupações auto-reportados",
    "dataset": "Experimento controlado com 30 participantes (18 homens, 12 mulheres, idade 19-37 anos, média 25.2±4.06), 4 condições experimentais por participante em ordem randomizada, tarefa de navegação de 90m com 5 checkpoints",
    "frameworks": "Unity 2020.4.25f (ambiente VR), Crest Ocean System (simulação oceânica de alta fidelidade), Unity Visual Effect Graph VFX (simulação de poeira flutuante), Python-Unity-Socket (comunicação Unity-Python), HTC VIVE HMD (display de realidade virtual), Tobii Pro Eye Tracker (rastreamento ocular a 50Hz integrado ao HTC VIVE), bHaptics TactSuit X40 (traje háptico com 40 vibradores), Xbox Controller (controle do ROV), Scripts C# para coleta de dados de trajetória e eye tracking, Self-Assessment Manikin SAM (referenciado mas não usado diretamente), NASA-TLX (avaliação de carga de trabalho), Trust Scale Survey (avaliação de confiança)",
    "link_codigo": "https://drive.google.com/file/d/1PNwltmf9QbNdM5_Be4AOUnAvLP5xc2Bf/view?usp=share_link (vídeo demonstrativo do sistema de feedback)"
  }
]
